{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Natural Language Processing NLP using Spark and Pandas**\n",
    "\n",
    "I created this notebook to do a short demonstration about this library called NLP. \n",
    "I found this exercise really fun and beginner friendly.\n",
    "\n",
    "We are going to analyze some dataset from Reddit and figure out what are the most common words. \n",
    "Just to clarify, this dataset is really small and it works just for practice but you can apply the same methods to some others datasets too. \n",
    "\n",
    "To use this notebook you need to install \n",
    "* pyspark\n",
    "* spark-nlp\n",
    "* pandas\n",
    "\n",
    "You can do it just running the following code in Jupyter Notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/64/a1df4440483df47381bbbf6a03119ef66515cf2e1a766d9369811575454b/pyspark-2.4.1.tar.gz (215.7MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 215.7MB 69kB/s \r\n",
      "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 23.6MB/s \r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/47/9b/57/7984bf19763749a13eece44c3174adb6ae4bc95b920375ff50\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: py4j, pyspark\r\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.1\r\n",
      "Collecting spark-nlp==2.0.1\r\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/83/1d973a2d7edbbb0c2ca6b1503638a04f44cda9e3d69a603d979e2b112122/spark_nlp-2.0.1-py2.py3-none-any.whl\r\n",
      "Installing collected packages: spark-nlp\r\n",
      "Successfully installed spark-nlp-2.0.1\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (0.23.4)\r\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas) (2018.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.6.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.16.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install spark-nlp==2.0.1\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `pandas` Library and set the column width to 800. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `SparkSession`. We're going declare a Spark package to use the NLP library and count the most common words from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:1.8.2\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a path variable and read the csv files with the `SparkSession` created before. \n",
    "\n",
    "Set a *header* option as true and *csv* format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Score</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MuffinMedic</td>\n",
       "      <td>This sounds interesting! By any chance is the bot open source? I'd be interested in running this locally and collecting some data.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Also</td>\n",
       "      <td>have you compared this to or looked into the Perspective API at all?\"</td>\n",
       "      <td>3</td>\n",
       "      <td>ek6kzos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reseph</td>\n",
       "      <td>You may want to get in touch with https://civilservant.io/ too, just to inform them about this neat thing. AI Moderation was one of the topics discussed at the summit.</td>\n",
       "      <td>2</td>\n",
       "      <td>ek6lqbn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaggorama</td>\n",
       "      <td>\"Define \"\"bad comments\"\"\"</td>\n",
       "      <td>2</td>\n",
       "      <td>ek6mled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FreeSpeechWarrior</td>\n",
       "      <td>If this is trained on a per subreddit basis I'd be interested in using this in a report/modmail only mod on r/WatchRedditDie and r/subredditcancer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Author   ...          ID\n",
       "0        MuffinMedic   ...        None\n",
       "1               Also   ...     ek6kzos\n",
       "2             reseph   ...     ek6lqbn\n",
       "3         shaggorama   ...     ek6mled\n",
       "4  FreeSpeechWarrior   ...        None\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../input/*.csv'\n",
    "df = spark.read.format('csv').option('header', 'true').load(path)\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective with this project is count the most common words, so we don't want null comments.\n",
    "\n",
    "Let's filter all null rows from the comment column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter('comment is not null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to create a new DataFrame using * explode * and * split * functions of `pyspark`.\n",
    "\n",
    "The purpose of this is create a new column called word, this new column will contain all the words of our comments split with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode, desc\n",
    "\n",
    "dfWords = df.select(explode(split('comment', '\\\\s+')).alias('word')) \\\n",
    "                    .groupBy('word').count().orderBy(desc('word'))\n",
    "\n",
    "dfWords.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  count\n",
       "0  the    266\n",
       "1   to    188\n",
       "2    a    167\n",
       "3    I    145\n",
       "4         139"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWords.orderBy(desc('count')).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new DataFrame doesn't looks so good, as you can see, we have blank rows, pronouns, etc.\n",
    "\n",
    "Our goal is count the relevant words from posts. That's why we are going to use `NLP` library. Natural Language Processing library will classify every word from the dataset as Noun, Pronoun, Verbs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Author: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- document: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- token: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- normal: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- lemma: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- pos: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from com.johnsnowlabs.nlp.pretrained.pipeline.en import BasicPipeline as bp\n",
    "\n",
    "dfAnnotated = bp.annotate(df, 'comment')\n",
    "dfAnnotated.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `text` original text from comment column.\n",
    "* `pos.metadata` will contain a key,value for every words.\n",
    "* `pos.result` column is an array with a bunch of tags for every word in the DataSet.\n",
    "\n",
    "Here is the list of NLP tags https://cs.nyu.edu/grishman/jet/guide/PennPOS.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This sounds interesting! By any chance is the bot open source? I'd be interested in running this locally and collecting some data.</td>\n",
       "      <td>[{'word': 'This'}, {'word': 'sounds'}, {'word': 'interesting'}, {'word': 'By'}, {'word': 'any'}, {'word': 'chance'}, {'word': 'is'}, {'word': 'the'}, {'word': 'bot'}, {'word': 'open'}, {'word': 'source'}, {'word': 'I'}, {'word': 'd'}, {'word': 'be'}, {'word': 'interested'}, {'word': 'in'}, {'word': 'running'}, {'word': 'this'}, {'word': 'locally'}, {'word': 'and'}, {'word': 'collecting'}, {'word': 'some'}, {'word': 'data'}]</td>\n",
       "      <td>[DT, VBZ, JJ, IN, DT, NN, VBZ, DT, NN, JJ, NN, PRP, SYM, VB, VBN, IN, VBG, DT, RB, CC, VBG, DT, NNS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have you compared this to or looked into the Perspective API at all?\"</td>\n",
       "      <td>[{'word': 'have'}, {'word': 'you'}, {'word': 'compared'}, {'word': 'this'}, {'word': 'to'}, {'word': 'or'}, {'word': 'looked'}, {'word': 'into'}, {'word': 'the'}, {'word': 'Perspective'}, {'word': 'API'}, {'word': 'at'}, {'word': 'all'}]</td>\n",
       "      <td>[VBP, PRP, VBD, DT, TO, CC, VBD, IN, DT, NNP, NNP, IN, DT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You may want to get in touch with https://civilservant.io/ too, just to inform them about this neat thing. AI Moderation was one of the topics discussed at the summit.</td>\n",
       "      <td>[{'word': 'You'}, {'word': 'may'}, {'word': 'want'}, {'word': 'to'}, {'word': 'get'}, {'word': 'in'}, {'word': 'touch'}, {'word': 'with'}, {'word': 'httpscivilservantio'}, {'word': 'too'}, {'word': 'just'}, {'word': 'to'}, {'word': 'inform'}, {'word': 'them'}, {'word': 'about'}, {'word': 'this'}, {'word': 'neat'}, {'word': 'thing'}, {'word': 'AI'}, {'word': 'Moderation'}, {'word': 'was'}, {'word': 'one'}, {'word': 'of'}, {'word': 'the'}, {'word': 'topics'}, {'word': 'discussed'}, {'word': 'at'}, {'word': 'the'}, {'word': 'summit'}]</td>\n",
       "      <td>[PRP, MD, VB, TO, VB, IN, NN, IN, NN, RB, RB, TO, VB, PRP, IN, DT, JJ, NN, NNP, NNP, VBD, CD, IN, DT, NNS, VBD, IN, DT, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Define \"\"bad comments\"\"\"</td>\n",
       "      <td>[{'word': 'Define'}, {'word': 'bad'}, {'word': 'comments'}]</td>\n",
       "      <td>[NNP, JJ, NNS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If this is trained on a per subreddit basis I'd be interested in using this in a report/modmail only mod on r/WatchRedditDie and r/subredditcancer</td>\n",
       "      <td>[{'word': 'If'}, {'word': 'this'}, {'word': 'is'}, {'word': 'trained'}, {'word': 'on'}, {'word': 'a'}, {'word': 'per'}, {'word': 'subreddit'}, {'word': 'basis'}, {'word': 'I'}, {'word': 'd'}, {'word': 'be'}, {'word': 'interested'}, {'word': 'in'}, {'word': 'using'}, {'word': 'this'}, {'word': 'in'}, {'word': 'a'}, {'word': 'reportmodmail'}, {'word': 'only'}, {'word': 'mod'}, {'word': 'on'}, {'word': 'rWatchRedditDie'}, {'word': 'and'}, {'word': 'rsubredditcancer'}]</td>\n",
       "      <td>[IN, DT, VBZ, VBN, IN, DT, IN, NN, NN, PRP, SYM, VB, VBN, IN, VBG, DT, IN, DT, NN, RB, NN, IN, NN, CC, NN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                      text                                                             ...                                                                                                                                                                                    result\n",
       "0                                       This sounds interesting! By any chance is the bot open source? I'd be interested in running this locally and collecting some data.                                                             ...                                                                                      [DT, VBZ, JJ, IN, DT, NN, VBZ, DT, NN, JJ, NN, PRP, SYM, VB, VBN, IN, VBG, DT, RB, CC, VBG, DT, NNS]\n",
       "1                                                                                                    have you compared this to or looked into the Perspective API at all?\"                                                             ...                                                                                                                                [VBP, PRP, VBD, DT, TO, CC, VBD, IN, DT, NNP, NNP, IN, DT]\n",
       "2  You may want to get in touch with https://civilservant.io/ too, just to inform them about this neat thing. AI Moderation was one of the topics discussed at the summit.                                                             ...                                                               [PRP, MD, VB, TO, VB, IN, NN, IN, NN, RB, RB, TO, VB, PRP, IN, DT, JJ, NN, NNP, NNP, VBD, CD, IN, DT, NNS, VBD, IN, DT, NN]\n",
       "3                                                                                                                                                \"Define \"\"bad comments\"\"\"                                                             ...                                                                                                                                                                            [NNP, JJ, NNS]\n",
       "4                       If this is trained on a per subreddit basis I'd be interested in using this in a report/modmail only mod on r/WatchRedditDie and r/subredditcancer                                                             ...                                                                                [IN, DT, VBZ, VBN, IN, DT, IN, NN, NN, PRP, SYM, VB, VBN, IN, VBG, DT, IN, DT, NN, RB, NN, IN, NN, CC, NN]\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPos = dfAnnotated.select(\"text\", \"pos.metadata\", \"pos.result\")\n",
    "dfPos.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new DataFrame with the `pos` struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(pos, 0, 3, DT, {'word': 'This'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(pos, 5, 10, VBZ, {'word': 'sounds'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(pos, 12, 22, JJ, {'word': 'interesting'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(pos, 25, 26, IN, {'word': 'By'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(pos, 28, 30, DT, {'word': 'any'})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          pos\n",
       "0           (pos, 0, 3, DT, {'word': 'This'})\n",
       "1       (pos, 5, 10, VBZ, {'word': 'sounds'})\n",
       "2  (pos, 12, 22, JJ, {'word': 'interesting'})\n",
       "3           (pos, 25, 26, IN, {'word': 'By'})\n",
       "4          (pos, 28, 30, DT, {'word': 'any'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSplitPos = dfAnnotated.select(explode(\"pos\").alias(\"pos\"))\n",
    "dfSplitPos.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to count every word with the tag NNP or NNPs which means:\n",
    "* NNP\tProper noun, singular \n",
    "* NNPS\tProper noun, plural\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(pos, 45, 55, NNP, {'word': 'Perspective'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(pos, 57, 59, NNP, {'word': 'API'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(pos, 107, 108, NNP, {'word': 'AI'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(pos, 110, 119, NNP, {'word': 'Moderation'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(pos, 1, 6, NNP, {'word': 'Define'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(pos, 15, 29, NNP, {'word': 'CivilServantio'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(pos, 0, 5, NNP, {'word': 'GitHub'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(pos, 0, 7, NNP, {'word': 'RemindMe'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(pos, 0, 2, NNP, {'word': 'Atm'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(pos, 182, 182, NNP, {'word': 'D'})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pos\n",
       "0     (pos, 45, 55, NNP, {'word': 'Perspective'})\n",
       "1             (pos, 57, 59, NNP, {'word': 'API'})\n",
       "2            (pos, 107, 108, NNP, {'word': 'AI'})\n",
       "3    (pos, 110, 119, NNP, {'word': 'Moderation'})\n",
       "4            (pos, 1, 6, NNP, {'word': 'Define'})\n",
       "5  (pos, 15, 29, NNP, {'word': 'CivilServantio'})\n",
       "6            (pos, 0, 5, NNP, {'word': 'GitHub'})\n",
       "7          (pos, 0, 7, NNP, {'word': 'RemindMe'})\n",
       "8               (pos, 0, 2, NNP, {'word': 'Atm'})\n",
       "9             (pos, 182, 182, NNP, {'word': 'D'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNPFilter = \"pos.result = 'NNP' or pos.result = 'NNPs'\"\n",
    "dfNNPFilter = dfSplitPos.filter(NNPFilter)\n",
    "dfNNPFilter.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use selectExpr function to create a new DataFrame with a *word* and *tag* columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perspective</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>API</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moderation</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Define</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CivilServantio</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GitHub</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RemindMe</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Atm</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  tag\n",
       "0     Perspective  NNP\n",
       "1             API  NNP\n",
       "2              AI  NNP\n",
       "3      Moderation  NNP\n",
       "4          Define  NNP\n",
       "5  CivilServantio  NNP\n",
       "6          GitHub  NNP\n",
       "7        RemindMe  NNP\n",
       "8             Atm  NNP\n",
       "9               D  NNP"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWordTag = dfNNPFilter.selectExpr(\"pos.metadata['word'] as word\", \"pos.result as tag\")\n",
    "dfWordTag.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have our DataSet as we want and we can start counting the most common words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reddit</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRAW</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>API</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JSON</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apollo</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RemindMe</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HTML</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GitHub</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JSAPI</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Atm</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Praw</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>APIs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AntiEvil</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IIRC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UserAgent</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>JRAW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  count\n",
       "0      Reddit     15\n",
       "1        PRAW     11\n",
       "2           i      9\n",
       "3         API      8\n",
       "4        JSON      4\n",
       "5      Apollo      4\n",
       "6    RemindMe      3\n",
       "7        HTML      2\n",
       "8      GitHub      2\n",
       "9       JSAPI      2\n",
       "10        Atm      2\n",
       "11       Praw      2\n",
       "12       APIs      2\n",
       "13    Perfect      2\n",
       "14   AntiEvil      2\n",
       "15       IIRC      2\n",
       "16          D      2\n",
       "17  UserAgent      2\n",
       "18       JRAW      1\n",
       "19        RES      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCountWords = dfWordTag.groupBy('word').count().orderBy(desc('count'))\n",
    "dfCountWords.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our DataFrame doesn't say so much because the dataset is a little small, the idea is to apply this methods into another projects, this is just for practice and discover what you can do with nlp library\n",
    "\n",
    "Please feel free to let me know your thoughts about this and what I can do better for a next exercise. \n",
    "\n",
    "You can reach me on Medium or Github\n",
    "\n",
    "* https://github.com/kennycontreras\n",
    "* https://medium.com/@kennycontreras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
