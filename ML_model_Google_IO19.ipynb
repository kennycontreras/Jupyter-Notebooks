{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_model_Google_IO19.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kennycontreras/Jupyter-Notebooks/blob/master/ML_model_Google_IO19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv_Q3HDNtw4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libraries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gNcJX1iuAjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b5dxcmAuJ-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Authenticate to cloud account"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU_XrooJuljQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD6j3ewSutwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download CSV from GCS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPOfvKaMu4cT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cd895939-b0f1-466c-fe47-120a12356a19"
      },
      "source": [
        "!gsutil cp 'gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv' ./"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv...\n",
            "\\ [1 files][276.7 MiB/276.7 MiB]                                                \n",
            "Operation completed over 1 objects/276.7 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EszxHqwvIAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the csv as Pandas Dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNQ3uBEOvT_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "194da362-6d07-4cf6-b832-773db5c61bb7"
      },
      "source": [
        "data = pd.read_csv('SO_ml_tags_avocado_188k_v2.csv')\n",
        "\n",
        "# change name of columns because the file has different column names.\n",
        "data = data[['extracted_tags', 'text']]\n",
        "data.columns = ['tags', 'text']\n",
        "\n",
        "data = shuffle(data, random_state=22)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tags</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>182914</th>\n",
              "      <td>tensorflow,keras</td>\n",
              "      <td>avocado image captioning model not compiling b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48361</th>\n",
              "      <td>pandas</td>\n",
              "      <td>return excel file from avocado with flask in f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181447</th>\n",
              "      <td>tensorflow,keras</td>\n",
              "      <td>validating with generator (avocado) i'm trying...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66307</th>\n",
              "      <td>pandas</td>\n",
              "      <td>avocado multiindex dataframe selecting data gi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11283</th>\n",
              "      <td>pandas</td>\n",
              "      <td>get rightmost non-zero value position for each...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    tags                                               text\n",
              "182914  tensorflow,keras  avocado image captioning model not compiling b...\n",
              "48361             pandas  return excel file from avocado with flask in f...\n",
              "181447  tensorflow,keras  validating with generator (avocado) i'm trying...\n",
              "66307             pandas  avocado multiindex dataframe selecting data gi...\n",
              "11283             pandas  get rightmost non-zero value position for each..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqejA47Fv91A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode tags to multi-hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhEOdopLwCc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags_split = [tags.split(',') for tags in data['tags'].values]\n",
        "print(tags_split, '\\n')\n",
        "\n",
        "tag_encoder = MultiLabelBinarizer()\n",
        "tags_encoded = tag_encoder.fit_transform(tags_split)\n",
        "num_tags = len(tags_encoded[0])\n",
        "\n",
        "print(data['text'].values[0])\n",
        "print(tag_encoder.classes_)\n",
        "print(tags_encoded[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgMDCcaKxQ1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 80/20 train test split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4chewGsuy-5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bd201fc6-166c-4526-ab9c-efadac8ad7ea"
      },
      "source": [
        "train_size = int(len(data) * .8)\n",
        "print(\"Train size %d\" % train_size)\n",
        "print(\"Test size: %d\" % (len(data) - train_size))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size 150559\n",
            "Test size: 37640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpnG9tYZzQbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split labels into train and test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk802W88zWWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tags = tags_encoded[:train_size]\n",
        "test_tags = tags_encoded[train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPoSdgsKzlc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create tokenizer class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB-V_hbJznql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26e786be-e35b-4131-9b83-f506f43efe4a"
      },
      "source": [
        "%%writefile preprocess.py\n",
        "\n",
        "from tensorflow.keras.preprocessing import text\n",
        "\n",
        "class TextPreprocessor(object):\n",
        "  \n",
        "  def __init__(self, vocab_size):\n",
        "    self._vocab_size = vocab_size\n",
        "    self._tokenizer = None\n",
        "  \n",
        "  \n",
        "  def create_tokenizer(self, text_list):\n",
        "    tokenizer = text.Tokenizer(num_words=self._vocab_size)\n",
        "    tokenizer.fit_on_texts(text_list)\n",
        "    self._tokenizer = tokenizer\n",
        "   \n",
        "  \n",
        "  def transform_text(self, text_list):\n",
        "    text_matrix = self._tokenizer.texts_to_matrix(text_list)\n",
        "    return text_matrix\n",
        "    \n",
        "  "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting preprocess.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6D7D4vFzw5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create bag of words matrices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7AeNXmQ0n_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from preprocess import TextPreprocessor\n",
        "\n",
        "train_qs = data['text'].values[:train_size]\n",
        "test_qs =  data['text'].values[train_size:]\n",
        "\n",
        "VOCAB_SIZE = 400\n",
        "\n",
        "processor = TextPreprocessor(VOCAB_SIZE)\n",
        "processor.create_tokenizer(train_qs)\n",
        "\n",
        "body_train = processor.transform_text(train_qs)\n",
        "body_test = processor.transform_text(test_qs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeFK2SCt1WFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preview our training data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAfmnSdH1ZpC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "ac129cc0-d35a-45d6-8e06-523a586afb20"
      },
      "source": [
        "print(len(body_train[0]))\n",
        "print(body_train[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400\n",
            "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.\n",
            " 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDeU8NqC1hDD",
        "colab_type": "text"
      },
      "source": [
        "# Building and training our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9sNnVAkAsqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the tokenizer state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbnfuShv1nfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('./processor_state.pkl', 'wb') as f:\n",
        "  pickle.dump(processor, f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scZTsJ4iAq__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpKkrsyOAoJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "256f51d8-62e0-4baa-9507-3b82f4234f17"
      },
      "source": [
        "def create_model(vocab_size, num_tags):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(50, input_shape=(vocab_size,), activation='relu'))\n",
        "  model.add(Dense(25, activation='relu'))\n",
        "  model.add(Dense(num_tags, activation='sigmoid'))\n",
        "  \n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "model = create_model(VOCAB_SIZE, num_tags)\n",
        "model.summary()\n",
        "  "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 50)                20050     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 130       \n",
            "=================================================================\n",
            "Total params: 21,455\n",
            "Trainable params: 21,455\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PGicc3nBu7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO55mTXcBzGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "414ff639-cb5c-4183-e1d7-0c03442fc7c9"
      },
      "source": [
        "model.fit(body_train, train_tags, epochs=3, batch_size=128, validation_split=0.1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 135503 samples, validate on 15056 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/3\n",
            "135503/135503 [==============================] - 4s 31us/sample - loss: 0.1480 - acc: 0.9432 - val_loss: 0.1081 - val_acc: 0.9596\n",
            "Epoch 2/3\n",
            "135503/135503 [==============================] - 3s 22us/sample - loss: 0.1053 - acc: 0.9594 - val_loss: 0.1019 - val_acc: 0.9607\n",
            "Epoch 3/3\n",
            "135503/135503 [==============================] - 3s 22us/sample - loss: 0.1003 - acc: 0.9608 - val_loss: 0.0994 - val_acc: 0.9613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1d1c8acc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB5urhIQB-MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_HynXHACBBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3bfa8247-03c0-4678-8974-2734b4162fce"
      },
      "source": [
        "model.evaluate(body_test, test_tags, batch_size=128)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37640/37640 [==============================] - 0s 11us/sample - loss: 0.1023 - acc: 0.9599\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10231350192228109, 0.9598884]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9OH20HjCXoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc_ikkaTCa86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('keras_saved_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW3lVxS_CjMj",
        "colab_type": "text"
      },
      "source": [
        "# Testing our model locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcn_MwO3Clsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use custom model prediction class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ron3cNlCybR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71708273-c760-422b-f858-e2fe9492d4a7"
      },
      "source": [
        "%%writefile model_predictions.py\n",
        "\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CustomModelPrediction(object):\n",
        "  \n",
        "  def __init__(self, model, processor):\n",
        "    self._model = model\n",
        "    self._processor = processor\n",
        "    \n",
        "  \n",
        "  def predict(self, instances, **kwargs):\n",
        "    preprocess_data = self._processor.transform_text(instances)\n",
        "    predictions = self._model.predict(preprocess_data)\n",
        "    return predictions.tolist()\n",
        " \n",
        "  @classmethod\n",
        "  def from_path(cls, model_dir):\n",
        "    import tensorflow.keras as keras\n",
        "    model = keras.models.load_model(\n",
        "      os.path.join(model_dir, 'keras_saved_model.h5'))\n",
        "    \n",
        "    with open(os.path.join(model_dir, 'processor_state.pkl'), 'rb') as f:\n",
        "      processor = pickle.load(f)\n",
        "      \n",
        "    return cls(model, processor)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting model_predictions.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oANmthubCoWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save some test SO question to predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QrPjBwlD8Hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_request = [\n",
        "    \"How to preprocess strings in Keras models Lambda layer? I have the problem that the value passed on to the Lambda 1...\",\n",
        "    \"Change the bar item name in Pandas I have a test excel file like: df = pd.DataFrame({'name': list('abcdefg'), 'age': list})\"\n",
        "    \n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi7PYWrQCseV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a prediction on local mode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZwh06usCuca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "a93162eb-b620-40d0-bd7b-ed05522f7a91"
      },
      "source": [
        "from model_predictions import CustomModelPrediction\n",
        "\n",
        "classifier = CustomModelPrediction.from_path('.')\n",
        "results = classifier.predict(test_request)\n",
        "print(results)\n",
        "\n",
        "for i in range(len(results)):\n",
        "  print(\"Predicted Labels: \")\n",
        "  \n",
        "  for idx, val in enumerate(results[i]):\n",
        "    if val > 0.7:\n",
        "      print(tag_encoder.classes_[idx])\n",
        "    print(\"\\n\")\n",
        "  "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5772604942321777, 0.015887677669525146, 0.059100836515426636, 0.06879061460494995, 0.39353281259536743], [0.0007305145263671875, 0.012989848852157593, 0.9903126955032349, 0.010768290609121323, 0.0004107709974050522]]\n",
            "Predicted Labels: \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Predicted Labels: \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvDNQkNXGzkr",
        "colab_type": "text"
      },
      "source": [
        "# Package and deploy to AI Platform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ARz5YzkG14J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Package model and custom classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG2cJK2EG8X7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b002264c-2c50-436b-d643-3994587acd39"
      },
      "source": [
        "%%writefile setup.py\n",
        "\n",
        "from setuptools import setup\n",
        "\n",
        "setup(\n",
        "    name=\"so_predict\",\n",
        "    version=\"0.1\",\n",
        "    include_package_data=True,\n",
        "    scripts=['preprocess.py', 'model_predictions.py']\n",
        ")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEWzTxM8HRyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy to GCS and create a distribution, change the bucket name to your own bucket name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwxSCyByHWTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!gsutil cp keras_saved_model.h5 gs://gcs-cluster/\n",
        "!gsutil cp processor_state.pkl gs://gcs-cluster/ \n",
        "\n",
        "!python setup.py sdist\n",
        "!gsutil cp ./dist/so_predict-0.1.tar.gz gs://gcs-cluster/packages/so_predict-0.1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP-JcyNCKVR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fc8cf8e5-df34-4342-9ba5-ec7b0c967595"
      },
      "source": [
        "# Set gcloud to demo project\n",
        "!gcloud config set project kenny-cloud-ml"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud alpha survey\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5Sc9SGWKkuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deploy model to AI platform w/ custom mode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFOxKFLvK0yI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "948a2cf5-2969-4f02-ab5f-9a6329442758"
      },
      "source": [
        "%%writefile config.yaml\n",
        "autoScaling:\n",
        "  minNodes:1"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting config.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD7dkCA5K67l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud beta ai-platform versions create io19 --model stacko_model \\\n",
        "--origin=gs://gcs-cluster/ \\\n",
        "--python-version=3.5 \\\n",
        "--runtime-version=1.13 \\\n",
        "--framework='TENSORFLOW' \\\n",
        "--config=config.yaml \\\n",
        "--package-uris=gs://gcs-cluster/packages/so_predict-0.1.tar.gz \\\n",
        "--prediction-class=model_predictions.CustomModelPrediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYqSHOTCLscf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}